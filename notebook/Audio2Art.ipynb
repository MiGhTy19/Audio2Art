{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iMe4FO44gSL"
   },
   "outputs": [],
   "source": [
    "## Audio2Art: Transforming Voice Prompts into Visual Creations using Transformers\n",
    "\n",
    "## This project converts voice prompts into images using transformer models.\n",
    "# Created by Ayush Prajapati, Rutu Bhatt, Dipen Trivedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-fvLfNQ5Vqu"
   },
   "outputs": [],
   "source": [
    "## Before running the first cell:\n",
    "## Go to Runtime â†’ Change runtime type Set Hardware accelerator to T4 GPU (Recommended for Stable Diffusion speed and compatibility).\n",
    "\n",
    "## Step 1: Install Required Libraries\n",
    "\n",
    "## First, let's install the necessary packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUfFMA9p5cYu",
    "outputId": "2aedad6b-b1f0-4af1-edb5-84cb927539b5"
   },
   "outputs": [],
   "source": [
    "# Install Python libraries\n",
    "%pip install streamlit diffusers accelerate transformers librosa torch soundfile\n",
    "\n",
    "# For speech-to-text with Wav2Vec\n",
    "%pip install datasets jiwer\n",
    "\n",
    "# Install Node.js and localtunnel\n",
    "!apt-get update\n",
    "!apt-get install -y nodejs npm\n",
    "!npm install -g localtunnel\n",
    "\n",
    "print(\"All required libraries installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvj0nZPL6Bks"
   },
   "outputs": [],
   "source": [
    "## Step 2: Create and Initialize the Models\n",
    "\n",
    "## In this step, we'll create our ImageModel class that handles both speech-to-text and text-to-image conversion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWKp38Oc6IOc",
    "outputId": "e9e76874-c7a1-4f8c-d35a-eb0fad14a1da"
   },
   "outputs": [],
   "source": [
    "%%writefile ImageModel.py\n",
    "\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import soundfile as sf\n",
    "import librosa as lb\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Literal, Tuple\n",
    "from PIL import Image\n",
    "\n",
    "def promptgen(file):\n",
    "    \"\"\"\n",
    "    Process an audio file and generate a transcription of its content.\n",
    "\n",
    "    Parameters:\n",
    "    file (str): Path to the audio file\n",
    "\n",
    "    Returns:\n",
    "    str: Transcribed text from the audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokenizer = Wav2Vec2Tokenizer.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "        model = Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-960h')\n",
    "\n",
    "        print(f\"Loading audio file: {file}\")\n",
    "        # Try to load the audio file with error handling\n",
    "        try:\n",
    "            waveform, rate = lb.load(file, sr=16000, mono=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio with librosa: {e}\")\n",
    "            # Try alternative loading with soundfile directly\n",
    "            import soundfile as sf\n",
    "            audio_data, rate = sf.read(file)\n",
    "            if len(audio_data.shape) > 1:  # Convert stereo to mono if needed\n",
    "                audio_data = audio_data.mean(axis=1)\n",
    "            waveform = lb.resample(audio_data, orig_sr=rate, target_sr=16000)\n",
    "\n",
    "        # Normalize the waveform\n",
    "        waveform = waveform / (np.max(np.abs(waveform)) + 1e-10)\n",
    "\n",
    "        # Process with Wav2Vec\n",
    "        input_values = tokenizer(waveform, return_tensors='pt').input_values\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        transcription = tokenizer.batch_decode(predicted_ids)\n",
    "\n",
    "        # If transcription is empty or just whitespace, return a default message\n",
    "        if not transcription[0].strip():\n",
    "            return \"a beautiful abstract painting with vibrant colors\"\n",
    "\n",
    "        return transcription[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in promptgen: {e}\")\n",
    "        # Return a default prompt in case of any error\n",
    "        return \"a beautiful abstract painting with vibrant colors\"\n",
    "\n",
    "def text2image(prompt: str, repo_id: Literal[\"runwayml/stable-diffusion-v1-5\",\n",
    "                                            \"CompVis/stable-diffusion-v1-4\",\n",
    "                                            \"stabilityai/stable-diffusion-2-1\"]) -> Tuple[Image.Image, float, float]:\n",
    "    \"\"\"\n",
    "    Generate an image from a text prompt using Stable Diffusion models.\n",
    "\n",
    "    Parameters:\n",
    "    prompt (str): Text description to generate the image from\n",
    "    repo_id (Literal): Repository ID of the Stable Diffusion model to use\n",
    "\n",
    "    Returns:\n",
    "    tuple: (generated image, start time, end time)\n",
    "    \"\"\"\n",
    "    # Set seed for reproducibility\n",
    "    seed = 2024\n",
    "    generator = torch.manual_seed(seed)\n",
    "\n",
    "    # Set constants for the image generation process\n",
    "    NUM_ITERS_TO_RUN = 1\n",
    "    NUM_INFERENCE_STEPS = 50\n",
    "    NUM_IMAGES_PER_PROMPT = 1\n",
    "\n",
    "    # Record start time\n",
    "    start = time.time()\n",
    "\n",
    "    # Initialize the pipeline based on GPU availability\n",
    "    if torch.cuda.is_available():\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            repo_id,\n",
    "            torch_dtype=torch.float16,\n",
    "            generator=generator\n",
    "        )\n",
    "        pipe = pipe.to(\"cuda\")\n",
    "    else:\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            repo_id,\n",
    "            torch_dtype=torch.float32,\n",
    "            generator=generator\n",
    "        )\n",
    "\n",
    "    # Generate images\n",
    "    images = []\n",
    "    for _ in range(NUM_ITERS_TO_RUN):\n",
    "        result = pipe(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "            num_images_per_prompt=NUM_IMAGES_PER_PROMPT,\n",
    "            generator=generator\n",
    "        )\n",
    "        images.extend(result.images)\n",
    "\n",
    "    # Record end time\n",
    "    end = time.time()\n",
    "\n",
    "    # Return the first generated image and timing information\n",
    "    return images[0], start, end\n",
    "\n",
    "\n",
    "class ImageModel:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the speech-to-text and text-to-image models\n",
    "        \"\"\"\n",
    "        # Check if GPU is available\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        # Initialize Speech-to-Text model (Wav2Vec2)\n",
    "        self.speech_model_name = \"facebook/wav2vec2-base-960h\"\n",
    "        self.speech_tokenizer = None\n",
    "        self.speech_model = None\n",
    "\n",
    "        # Initialize Text-to-Image model (Stable Diffusion)\n",
    "        self.image_model_name = \"runwayml/stable-diffusion-v1-5\"\n",
    "        self.image_generator = None\n",
    "\n",
    "        # Load models\n",
    "        self.load_speech_model()\n",
    "        self.load_image_model()\n",
    "\n",
    "    def load_speech_model(self):\n",
    "        \"\"\"\n",
    "        Load the speech-to-text model (Wav2Vec2)\n",
    "        \"\"\"\n",
    "        print(\"Loading speech-to-text model...\")\n",
    "        try:\n",
    "            self.speech_tokenizer = Wav2Vec2Tokenizer.from_pretrained(self.speech_model_name)\n",
    "            self.speech_model = Wav2Vec2ForCTC.from_pretrained(self.speech_model_name).to(self.device)\n",
    "            print(\"Speech-to-text model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading speech-to-text model: {e}\")\n",
    "\n",
    "    def load_image_model(self):\n",
    "        \"\"\"\n",
    "        Load the text-to-image model (Stable Diffusion)\n",
    "        \"\"\"\n",
    "        print(\"Loading text-to-image model...\")\n",
    "        try:\n",
    "            self.image_generator = StableDiffusionPipeline.from_pretrained(\n",
    "                self.image_model_name,\n",
    "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "            )\n",
    "            self.image_generator = self.image_generator.to(self.device)\n",
    "            print(\"Text-to-image model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading text-to-image model: {e}\")\n",
    "\n",
    "    def speech_to_text(self, audio_file_path):\n",
    "        \"\"\"\n",
    "        Convert speech to text using Wav2Vec2 model\n",
    "\n",
    "        Parameters:\n",
    "        audio_file_path (str): Path to the audio file\n",
    "\n",
    "        Returns:\n",
    "        str: Transcribed text\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load audio file\n",
    "            audio, sample_rate = sf.read(audio_file_path)\n",
    "\n",
    "            # Resample if necessary\n",
    "            if sample_rate != 16000:\n",
    "                audio = lb.resample(audio, orig_sr=sample_rate, target_sr=16000)\n",
    "                sample_rate = 16000\n",
    "\n",
    "            # Convert to mono if stereo\n",
    "            if len(audio.shape) > 1:\n",
    "                audio = audio.mean(axis=1)\n",
    "\n",
    "            # Normalize audio\n",
    "            audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "            # Process audio with Wav2Vec2\n",
    "            input_values = self.speech_tokenizer(\n",
    "                audio,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True\n",
    "            ).input_values.to(self.device)\n",
    "\n",
    "            # Generate transcription\n",
    "            with torch.no_grad():\n",
    "                logits = self.speech_model(input_values).logits\n",
    "\n",
    "            # Decode the prediction\n",
    "            predicted_ids = torch.argmax(logits, dim=-1)\n",
    "            transcription = self.speech_tokenizer.batch_decode(predicted_ids)[0]\n",
    "\n",
    "            print(f\"Transcription: {transcription}\")\n",
    "            return transcription\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in speech-to-text conversion: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def text_to_image(self, prompt, output_path=\"generated_image.png\"):\n",
    "        \"\"\"\n",
    "        Generate an image from text using Stable Diffusion\n",
    "\n",
    "        Parameters:\n",
    "        prompt (str): Text prompt for image generation\n",
    "        output_path (str): Path to save the generated image\n",
    "\n",
    "        Returns:\n",
    "        image: Generated image\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"Generating image from prompt: {prompt}\")\n",
    "\n",
    "            # Generate image from prompt\n",
    "            with torch.autocast(self.device):\n",
    "                image = self.image_generator(prompt).images[0]\n",
    "\n",
    "            # Save the image\n",
    "            image.save(output_path)\n",
    "            print(f\"Image saved to {output_path}\")\n",
    "            return image\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in text-to-image conversion: {e}\")\n",
    "            return None\n",
    "\n",
    "    def audio_to_image(self, audio_file_path, output_path=\"generated_image.png\"):\n",
    "        \"\"\"\n",
    "        Convert audio to image (speech-to-text followed by text-to-image)\n",
    "\n",
    "        Parameters:\n",
    "        audio_file_path (str): Path to the audio file\n",
    "        output_path (str): Path to save the generated image\n",
    "\n",
    "        Returns:\n",
    "        tuple: (transcription, image)\n",
    "        \"\"\"\n",
    "        # First convert speech to text\n",
    "        transcription = self.speech_to_text(audio_file_path)\n",
    "\n",
    "        if not transcription:\n",
    "            print(\"No transcription generated.\")\n",
    "            return None, None\n",
    "\n",
    "        # Then convert text to image\n",
    "        image = self.text_to_image(transcription, output_path)\n",
    "\n",
    "        return transcription, image\n",
    "\n",
    "# For testing\n",
    "if __name__ == \"__main__\":\n",
    "    model = ImageModel()\n",
    "    print(\"Models initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y23Ff8Wl6x4d"
   },
   "outputs": [],
   "source": [
    "## Step 3: Test the ImageModel\n",
    "\n",
    "## Let's create an instance of our model and test the text-to-image functionality:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ca2d3496367e46bab18c1ab0f0579349",
      "7d832598844b4b9b86119da13c3e53dd",
      "aad621afd96d41269c93634bfcab4be8",
      "8ddeebe71cc64958b9e78de76c7f8f25",
      "d14ea8bdebbb4ed08fb9cbc2dbd22bca",
      "663b4f3ab1e54a4e9d5182c92f64739c",
      "14b3d7feedda4eb8ae455eddf1dc9a38",
      "c9e13112966944dd8f575ed416001e4e",
      "40fc87e1d1ab472b96fe8d34fd19a517",
      "afec3b13d2084329988d917ba3e3bc69",
      "ba4335f3a197458b81006c4fef35952b",
      "f7d79d8d9bb0470c84fc4dfcf2bdc3e8",
      "a59b37dfaf9e422897168a3ca3016c11",
      "f54b00600808471294fce4ae6a29562b",
      "641bd55cf86b447fab3326e50085f844",
      "846c5f97372c47bd981054520b18c0bb",
      "2782695a396543e98bd3aee6ca0b5c8c",
      "3a11edd4b3b04cc4bbe301a701f6278e",
      "f0f33845db7a4f698c8aa3eadf185d58",
      "e30e314ee4d242b685317f36bbee59f5",
      "7977993f83c2401a8a74179b677de21d",
      "118b910e610b4489832e9f7b97398948",
      "d3b8a4f25de647c289daa87f6065526f",
      "d38a3504450944b39722f6183bfed875",
      "b4f8aaff817e41fe94fd02df47bba203",
      "db912e08269e484aa1bd7773dbfcf1d6",
      "115986d9e25c4d728e0bb18b41136f9a",
      "eb38a7d807d2439d9ae0df0696bcac36",
      "8c2cf7ad54f64dd6825abe1592a4c42d",
      "35ff06aed6134d25ab0f1126e76077d1",
      "3a8774520569494a915f9206f21b687b",
      "7dee4f706cba41f7b83bcce2ff070d19",
      "e78f9ee66fa5434cb5e400ba0b814653",
      "d52da0b2827449ecb1c7e70c5ec623d2",
      "b1bf3e33766d4bc7b5d95266dfdeb366",
      "1b99de794541477ebc91b385a2c51bee",
      "35908fee84fd41038a1ea843ad81ebce",
      "c2884cf8fc3d4e02854a93c8371d2632",
      "27e2569ad8de4707b56a25d879308cd7",
      "3842411e31314314be0504982bace639",
      "4ac8a56e67a74d58a9ea93ad2541835e",
      "96325a1a25314b5fb646340871d5047f",
      "14f29a4850554b289fd8a7aa9c2fee94",
      "54a43d27392847d0bf6be26d92eac4e3",
      "e15f80a12d2d4209b3337fd9cbaba2ad",
      "c09b437ca8364743958b23cf493a7ec5",
      "209a39d5d5654824989084d85789c900",
      "977eb6b105df4115adc055cd365b9900",
      "d1196aa95a86435bb0e1a400bca5f340",
      "ade5f31a713d4183a430920998426141",
      "19bc2c6433494a25ba4d91d090aad3f4",
      "8a17196cf9aa4e8aa2939ecc64ebdb70",
      "50ce9779d5684df8842d4e50a965517a",
      "57dbb2c8faec4c298bb477f8363addd6",
      "9511fcff0e034f6d8090e742d401831c",
      "e20701c8646c4f5986b1ff6c8b1d38fc",
      "e931c9306f714ba2b707b41175ab3d3d",
      "9c8cb6a2cdd24e7bb73c5b1ee94cbe04",
      "32fba7e1bf71453ba32434eda2dd2788",
      "85a0809eb3f0497484b129d5a5051901",
      "6ebdeda8bfc84ed8ba359b11c428f134",
      "dd90ed2b06234d338918f6be404d1062",
      "320a96d750ae4fb596f3a73e6b36f5f0",
      "75f2ec4c51d94101ad25be1e0c7404b0",
      "6ea7456e17bc40daa758af7022502c3a",
      "dd6b9e944d2348ee921e2de2330fa61a",
      "2b355f3eefa244af8494109eaae2b018",
      "8811067c39c64fcfa20a854ce5fc5459",
      "37daca149c3c45069ad710c54683d72b",
      "2107a7efe2a541a3bc2c40db144f1146",
      "166d5abd5e274795aa9a3ab47c7e2b01",
      "e24526c6326a4f52b74986a37f235128",
      "423c527c860644b7a32a9e799c8a07fc",
      "b21baf56843544ec9f80604cd8c99890",
      "fe6f77a98d664a64b2f1bbc781c53520",
      "988aab3853274c93aed7887197b6edee",
      "54cc18d1db7a41e2a01fa3682f1e653b",
      "11099eda07bc49e3a40921b06e41f383",
      "b0e72239d3de49668c51e2e90cd5c966",
      "b786e9dd800e4bd3af90154412d67a94",
      "64c6fe5d158c4ec59ce661f33d70251f",
      "1ead2268a9684c50bd1747da3036b1a1",
      "98146e0664154aa0b772e92dbb472acd",
      "6d95ed2cee6b406c87bb815744fee9a7",
      "2e924e435530405d9ffa2bb23d53b041",
      "11ed0431c18043239402996acffa1c26",
      "03e9d46e56ed4c99a7b53712ec89e1b7",
      "338e19a693d5406d8b63a1882d863c98",
      "aead884aa5084093b4440c08721e32e3",
      "9c7c5fc2c357479c94bd7f656a0c91d4",
      "4bc6c4c2636a4a6883f7f2a0d2f52bb6",
      "1269dd2be4474c82a7d8df3511fcd30e",
      "56459bd9fba743bbb4c26cbc2922313e",
      "22310cbcf47f4f4a8271f3f09aac4217",
      "ed63bb55cd5d4ad4b2a04795a15224dc",
      "c76ffcd127f44bef890113511de081a4",
      "41ba252fe6ae4e7595e88dbb3224db11",
      "81c9728ae47e4bd5ba6b975bc410e83b",
      "140ba3cbad004bd4862d485e67da55d7",
      "c5625455a79a45bbbf32f49cbe77d03b",
      "0a97f9f23e0e4ff883dcf5d6c60f7412",
      "1876862d8a2b41839ded578cfda5073a",
      "3d49346a50be40668b75b5f4d04edac1",
      "26c41451f59345acb53d99e8be8f48ba",
      "77297c4790054c5480788cf777cfaa10",
      "baa3536258e14fef8ebb1884254110fb",
      "604dfe340d564842803aaa0df56c47cf",
      "0ea2a3b317bb4634b8acc18d4d491299",
      "0157910c894a465b821b54374cb4d7e2",
      "c435c29236054278939eb6e0ba7132da",
      "e70c7a2afd6741699c4a2ff53534dddc",
      "f9ac4219f1864e25a43e1f6078705012",
      "9142f5ca898741e29f3a59fbc3c1a758",
      "9312ba7836e445669205a0418d30266d",
      "6164a54acd88468b941c46c2d0cce0a4",
      "29b9cb7c98d246dd9e2450b628946e8b",
      "6645cb4905d64421a621960788714fbf",
      "92b138cb482b4bb8b8466edc9889a932",
      "f9e98d162d6446f283fd4d7975dc954f",
      "6c3a33d598004992aaf69d8286418c49",
      "832b182c9fab4edaab7c623417f9c2d1",
      "c4e258a15e4248418be12d6f4b0b0916",
      "a970ecd0470346f199490e5468e5d151",
      "d15a38057bfb4177a6311923dfa348aa",
      "da2a92e616e6430ca369e60759d7548a",
      "8c3471a46ae145ce92ec8752f1596f94",
      "43601a4407d04087af7cfa3fd895dbe8",
      "0241d914940a4f3a969a2db45545c291",
      "30e503ef213e4986ad47a81f70bd89be",
      "3b8785c32dc04c8eaf5b39d221dadafe",
      "a302487b372c4d7fa52d759f8df52ac0",
      "8b2ac252529042ab9fbcc5bb9e864205",
      "8866002cc70746468f913875bf9a4569",
      "87e2b8f747434a1c9edcc6fec5ada874",
      "3fd2bd3c332d4645bdd072fed9b7fdda",
      "de7515acea8945cf977ee24d304aef32",
      "d667e75a403143ad9519ec661cf843ac",
      "33e11dbc37af475497fedf2392a3ca77",
      "ea71b86ba86843389b74f298461929a3",
      "1c8cf67a14934db8920c7ac0f0e7091e",
      "5f66386eac7d47a3bc9b4d6c09721447",
      "0f03c5647b8a4ae1b681e421b2174e50",
      "46090d99b0a748ed9ab80ce46ec7911a",
      "537543ae89b04cf490cdd0719fac13de",
      "adac37e13db044368f2abf50af423cf0",
      "4951f44c75b14725baee2cf6c0d4cfb3",
      "bd1e7add0ab1462da7868d3841df7fc3",
      "90e95d9e0c4243239d9e3047b839cf3d",
      "9bffe261b5e34f64a6ac5025b68045eb",
      "7583d31ae77c4461967cf72493de90aa",
      "de3ee113d59648339fee7976188b24ea",
      "45fb9593daec4a99b86d1765f5d435bf",
      "a78cd8f53f15466f9f9744b88719a791",
      "6376ae57003b4d34a38762f3ffa54c53",
      "78d8d2fe109b4f8398b3744c0de10bb5",
      "35e8ab8eee4946adbede175fc095e5cd",
      "843ee9ce320f4260bf4e8af4d01a53cc",
      "f1a90c900d784f2688f823f41905573a",
      "33c6ac9fa68b40bdb463955220c79bfe",
      "dabffd7de2e84a8ba8ae1830e25f5871",
      "b73376032d1f45f1bb514c55d044c934",
      "4a0287db36fd477098cf81cd50d09a08",
      "fe8ef0f1622b4942b6b4a200d7350862",
      "af90631fde934a6eac9a7ce17299dd95",
      "4a165465490c40e0808d6e95cb78ffe4",
      "03a202cfe8e548608a6ee79b2d602aa3",
      "232b6eb1a5614dd491855c2f16b5c7b4",
      "9bf892c646f04001b9000344c2bf14f8",
      "da079ad3646644198a154d025c035bb9",
      "00316e3472034c76865298a0c6c4aa0b",
      "7cdb31b41d254caf9e1a912f0e3734b2",
      "f735e46ae6b443d5a0a6a06d0d2d4056",
      "60f29b9a09964f798978521b71d2ff48",
      "8d4ac49d772645f4aaec38b26667a094",
      "04ad3a6e392146c29d4d810ade5e9a02",
      "cdc01cbb2cab47b9a5ab899875b10f7a",
      "bc317ba4e148423690840a8fccf3e267",
      "4350bc42489549b191f091cba2fded92",
      "b3e57a17f7f944e7a10fafb1c4f78fb2",
      "451155bb16c0482db9fa7a64810fd75e",
      "a298b28058364d599be0db512ca9adfc",
      "d6851a845ae74c12af16ee25c84e9e38",
      "02b5abc61a9e4412965ffacb8d52cdee",
      "769c66e5ff394754a25a7151971608ad",
      "1df93824d4ce43c886d60d43d7743427",
      "6c4908d7b9f8429aa9642712b2b1abd2",
      "e2d02c0718e04a56b1b8bf384ad22151",
      "1377b7537c034c84966fe07783c200eb",
      "58c2e6d1ec204f4eb0e0b2f291346e61",
      "291768ca04344d75ad6f7ab5a5406809",
      "b074cb60a2a24c8b90fd471aa975f214",
      "4f142398b79a47289343e48f4f7a15c1",
      "a7919ffb5db14b0c851e2719bfccc72f",
      "2c8f3e32b3824f00ab1189f191bc22ad",
      "7dbbdfd1da1944fabd45e8c9243168d5",
      "ee14e52eef5a45e5b250c80cbcfa1fb9",
      "12a3ed3472624cff84c7f7d6ba7d477f",
      "7553ea4377e34cc7b56f75fb4f888717",
      "8aaf289d5175439f994d93a9c9fdaf9c",
      "ead15d70d88446bd857cea55c4e55eaf",
      "578646d8618a4c70ab33f7df36881c60",
      "52f180a19f744c248cf977a707047871",
      "24354b03e85e4f768c4f040a7335ca35",
      "181b8e7c90e8441fa760b671a710704d",
      "7379f3e290d64514aa02c58dc7fb637e",
      "a49588bd7d514ccf83ee94dcaa12fea4",
      "62ae887ed77b49acb8e87ae129df6fea",
      "d80d792b62b342c39fa790d75629ce2a",
      "52c31227ef7543b48e5a6f58f24ffc39",
      "bfa83dc950954edeb2ecb32a154d1f7f",
      "fa9d687ae21d4c98a8415557dc7de781",
      "efcd3b0b12bd4283b31662c7ee8fedcf",
      "24fee10b9b634859ab0d3564888cfc83",
      "d93ea6484ec74acab15ad996323b9231",
      "ce171a52990b458ca3274adc901ae7b0",
      "bca37e028dfe4efcafcf083b4cf22536",
      "fb85cb1b07024f359cd6834b6f1eccb2",
      "72b2dd94054840ec9ab507ba139b72d6",
      "8038b59e6e5d403fb2cec455a03ea837",
      "eef305fcb23b4eefad055e7bcba07ab0",
      "1fcbe260e74045b39325f6cf1af6c709",
      "b129a4b08edf40f380ddaf0279b8a7c9",
      "7dd3d50907df42dfba0453151c37541e",
      "8526733461604078a7bc5a237d3d32e8",
      "d6ff86e5ce9c40a797e4067c049ca79a",
      "9c45a657fb0441dead2ef13a16ba5d68",
      "90b81e077e8f4438b8dbba41dda509c1",
      "09cc672f5701409ab92f8c9125eba835",
      "91e35020783e4ed6a4d98953cc218dcd",
      "ce2c3c938726436591fc91245332a2a7",
      "6dbe833f86364042999544f64f01e752",
      "bb05b34178844ca8b09a1c5bf5a501be",
      "faf54394fe534cd9b853fbc1aaa53843",
      "ff43973956bf47209d8cec47573ee7d7",
      "4cd0fd9edaf1494c820d865414885b17",
      "e05e5a403c9945778a595dbf217a40a6",
      "52779eef9d964c6193bb569a6c04d3b4",
      "3b968f117a0d4c4f8fd3e86ac2f197ca",
      "702fb91bddd64533adefe2068428f9dd",
      "cf1385ee5c0f4cad8e1932d32e64ac05",
      "58da957aa79d48cfb6b02d1ffc65e966",
      "ff15a168444d44d997c65802d8add08e",
      "ce06640cb0fd4960b04832d1ddd89057",
      "78ec510b9d98485ca8736a77ed7f3ece",
      "1c891faa27d24b2f97adb9c828d49f31",
      "ce318c658e86451ab17c8daa85cb92d5",
      "eb86478af624488fb1a61681f0efbe8a",
      "322f695d2f754de5993d37bfc2d80415",
      "5655a20050d34326a05486c9e9c207c2",
      "4cb52342d01844be9688c6877449eb6c",
      "acc9fe85e0604ecba5ce1fd993b6f910",
      "4c685006f86d4488835516bb7cd9c66e",
      "c0034b681bcc469d88b8c21ab5e6795b"
     ]
    },
    "id": "W_eNCnqy61DM",
    "outputId": "49b35e20-5015-4709-ddae-9e908b018f66"
   },
   "outputs": [],
   "source": [
    "# Test the ImageModel\n",
    "from ImageModel import ImageModel\n",
    "\n",
    "# Create instance of the model\n",
    "model = ImageModel()\n",
    "\n",
    "# Define input type with Literal for demonstration\n",
    "from typing import Literal\n",
    "OutputFormat = Literal[\"png\", \"jpg\"]\n",
    "output_format: OutputFormat = \"png\"\n",
    "\n",
    "# If we have a test audio file, we could test the full pipeline\n",
    "# Otherwise, we can test the text-to-image part\n",
    "test_prompt = \"A beautiful sunset over mountains with reflections in a lake\"\n",
    "output_path = f\"test_generated_image.{output_format}\"\n",
    "\n",
    "# Test text-to-image generation\n",
    "image = model.text_to_image(test_prompt, output_path)\n",
    "\n",
    "# Display the generated image\n",
    "from IPython.display import Image, display\n",
    "display(Image(output_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oupSjSy4ocFR"
   },
   "outputs": [],
   "source": [
    "## Step 4: Test the promptgen Function\n",
    "\n",
    "## Now let's test the speech-to-text functionality using the `promptgen` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQSTPAYF-4um",
    "outputId": "d7d30d5a-1470-472d-f8ba-7ee605b36c6b"
   },
   "outputs": [],
   "source": [
    "# Create a sample directory for audio files\n",
    "!mkdir -p sample_data\n",
    "\n",
    "# For testing the promptgen function, we need a sample audio file\n",
    "# In a real scenario, we would use a real audio file\n",
    "# Here, let's try to find if we have any audio file or create a simple one\n",
    "\n",
    "# Option 1: Check if there's a sample audio file in the sample_data directory\n",
    "import os\n",
    "if not any(f.endswith('.wav') for f in os.listdir('sample_data')):\n",
    "    # Option 2: Generate a simple sine wave audio file for testing\n",
    "    import numpy as np\n",
    "    import soundfile as sf\n",
    "\n",
    "    print(\"Creating a sample audio file...\")\n",
    "    # Create a simple sine wave\n",
    "    sample_rate = 16000\n",
    "    duration = 2  # seconds\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    audio = np.sin(2 * np.pi * 440 * t)  # 440 Hz sine wave\n",
    "\n",
    "    # Save as wav file\n",
    "    sf.write('sample_data/test_audio.wav', audio, sample_rate)\n",
    "    print(\"Sample audio file created at sample_data/test_audio.wav\")\n",
    "\n",
    "# Test the promptgen function with the sample audio file\n",
    "from ImageModel import promptgen\n",
    "\n",
    "try:\n",
    "    transcription = promptgen('sample_data/test_audio.wav')\n",
    "    print(f\"Transcription: {transcription}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error testing promptgen function: {e}\")\n",
    "    print(\"Note: In a real scenario, you would need an actual speech audio file for meaningful transcription.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftnnSJ-WpfLc"
   },
   "outputs": [],
   "source": [
    "## Step 5: Test the text2image Function\n",
    "\n",
    "## Let's test the `text2image` function separately:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628,
     "referenced_widgets": [
      "c6c9074301d84cdd96f6a74b7572c8f3",
      "4b341de15a7847d18509f5e807f02730",
      "d15b3d4bd6584ccbbb481ad99b4e2e9a",
      "48e0c93fc68149ca97c4029b92cd5c25",
      "ce3f379eaf6b4e7abe1085a191bf4b2a",
      "60ab68dd565a40f88e9e9cf4ace69acd",
      "2f3dbae2893d4d949e40f4000d68804b",
      "0f6774d1861b42c4847af26f1c167351",
      "08343253aa9149e79ebf3b90ff2595ca",
      "ef6dfb1081f048da90f10b3c5bc9fa85",
      "fdde9e809c5d4e208e9e6850c7fe908c",
      "2cd2720850bf4f5f89ed8e9d0d30fa02",
      "8390912eca2245e4a2d6d3ad046e9719",
      "5ace7641871e4ef184fd45058a2b7205",
      "c38ce544acfe460394211f5ecc6c9551",
      "a32ed9c325984149a42a256d5165f1c6",
      "d442f95dcf3e4dbe88e45f6b8ac6fd7c",
      "00c527672d834cd0b9325f91d2bf1465",
      "46019d02dcf64f5ea695e9d6b4ba914d",
      "7cbd8707690e4abcbab0b83983476f2c",
      "bea49a130be64c1694321016beb34017",
      "17d500853f8345a68b07e8ec3f40e39c"
     ]
    },
    "id": "Y_N5xAN8_REm",
    "outputId": "291a5651-a78b-4313-f66d-2fc3f05a857f"
   },
   "outputs": [],
   "source": [
    "# Test the text2image function\n",
    "from ImageModel import text2image\n",
    "\n",
    "test_prompt = \"A futuristic city with flying cars and tall skyscrapers\"\n",
    "repo_id = \"runwayml/stable-diffusion-v1-5\"  # Using v1-5 for better quality\n",
    "\n",
    "try:\n",
    "    # Generate the image and get timing information\n",
    "    generated_image, start_time, end_time = text2image(test_prompt, repo_id)\n",
    "\n",
    "    # Save the generated image\n",
    "    output_path = \"generated_city.png\"\n",
    "    generated_image.save(output_path)\n",
    "\n",
    "    # Display the generated image and timing info\n",
    "    from IPython.display import Image, display\n",
    "    print(f\"Image generation took {end_time - start_time:.2f} seconds\")\n",
    "    display(Image(output_path))\n",
    "except Exception as e:\n",
    "    print(f\"Error in text2image function: {e}\")\n",
    "    print(\"Note: This function requires significant computational resources.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QR4do2CvpkY5"
   },
   "outputs": [],
   "source": [
    "## Step 6: Create the Streamlit Web Application\n",
    "\n",
    "## Now let's create our Streamlit application with a user-friendly interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tE7MiMB_jod",
    "outputId": "a8ff09b0-7226-4c78-dd4a-1b6058dd984e"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "from ImageModel import promptgen, text2image\n",
    "from io import BytesIO\n",
    "import os\n",
    "import time\n",
    "from typing import Literal\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "\n",
    "def app():\n",
    "    # Set the title of the web page\n",
    "    st.title(\"Audio2Art: Transforming Audio Prompts into Visual Creations\")\n",
    "\n",
    "    # Create a file uploader for wav files\n",
    "    upload_file = st.file_uploader(\"Choose your .wav audio file\", type=[\"wav\"])\n",
    "\n",
    "    # Dropdown for selecting the model option\n",
    "    option = st.selectbox(\n",
    "        'Select Model',\n",
    "        (\"runwayml/stable-diffusion-v1-5\", \"CompVis/stable-diffusion-v1-4\", \"stabilityai/stable-diffusion-2-1\")\n",
    "    )\n",
    "\n",
    "    # Create session state to store results\n",
    "    if 'generated_image' not in st.session_state:\n",
    "        st.session_state.generated_image = None\n",
    "        st.session_state.image_buffer = None\n",
    "\n",
    "    # Create a form with a submit button\n",
    "    with st.form(\"my_form\"):\n",
    "        submit = st.form_submit_button(label=\"Submit Audio File!\")\n",
    "\n",
    "    # Process when submit is pressed (outside the form)\n",
    "    if submit:\n",
    "        if upload_file is not None:\n",
    "            # Show a spinner while processing\n",
    "            with st.spinner(\"Generating Image ... It may take some time.\"):\n",
    "                try:\n",
    "                    # Save uploaded file to a temporary file\n",
    "                    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:\n",
    "                        tmp_file.write(upload_file.getvalue())\n",
    "                        tmp_path = tmp_file.name\n",
    "\n",
    "                    # Generate prompt from audio using the file path\n",
    "                    prompt = promptgen(tmp_path)\n",
    "                    st.write(f\"Generated prompt: {prompt}\")\n",
    "\n",
    "                    # Clean up the temporary file\n",
    "                    os.unlink(tmp_path)\n",
    "\n",
    "                    # Generate image from prompt\n",
    "                    im, start, end = text2image(prompt, option)\n",
    "\n",
    "                    # Create a buffer for the image and store in session state\n",
    "                    buf = BytesIO()\n",
    "                    im.save(buf, format=\"PNG\")\n",
    "                    st.session_state.generated_image = im\n",
    "                    st.session_state.image_buffer = buf\n",
    "\n",
    "                    # Calculate processing time\n",
    "                    processing_time = end - start\n",
    "\n",
    "                    # Display success message with processing time\n",
    "                    st.success(f\"Image generated in {processing_time:.2f} seconds!\")\n",
    "\n",
    "                    # Display the generated image\n",
    "                    st.image(im)\n",
    "\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error processing audio: {str(e)}\")\n",
    "        else:\n",
    "            st.error(\"Please upload an audio file!\")\n",
    "\n",
    "    # Download button outside the form\n",
    "    if st.session_state.generated_image is not None:\n",
    "        st.download_button(\n",
    "            label=\"Download Image\",\n",
    "            data=st.session_state.image_buffer.getvalue(),\n",
    "            file_name=\"generated_image.png\",\n",
    "            mime=\"image/png\"\n",
    "        )\n",
    "\n",
    "    # Add sidebar with guide and examples\n",
    "    with st.sidebar:\n",
    "        st.header(\"How to use Audio2Art\")\n",
    "        st.write(\"\"\"\n",
    "        1. Upload a .wav audio file containing your voice prompt\n",
    "        2. Select the model you want to use\n",
    "        3. Click 'Submit Audio File!'\n",
    "        4. Wait for the image to be generated\n",
    "        5. Download the generated image if desired\n",
    "        \"\"\")\n",
    "\n",
    "        st.header(\"Examples\")\n",
    "        st.write(\"\"\"\n",
    "        Try these voice prompts:\n",
    "        - \"A beautiful sunset over mountains with reflections in a lake\"\n",
    "        - \"A futuristic city with flying cars and tall skyscrapers\"\n",
    "        - \"A cute puppy playing in a garden full of flowers\"\n",
    "        \"\"\")\n",
    "\n",
    "# Run the app when the script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    app()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whi7FRWtqezq"
   },
   "outputs": [],
   "source": [
    "## Step 7: Set Up the Deployment Environment\n",
    "\n",
    "## Let's create a deployment directory structure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlFGEXcY_orX",
    "outputId": "28d87561-9833-41df-c994-cccdee37b8fa"
   },
   "outputs": [],
   "source": [
    "# Create directories for our deployment\n",
    "!mkdir -p deployment/sample_data\n",
    "\n",
    "# Copy our key files to the deployment directory\n",
    "!cp ImageModel.py deployment/\n",
    "!cp app.py deployment/\n",
    "\n",
    "# Create directories for uploads and generated images\n",
    "!mkdir -p deployment/uploads\n",
    "!mkdir -p deployment/generated_images\n",
    "\n",
    "# List the deployment directory structure\n",
    "!ls -la deployment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s70EucOJqk4b"
   },
   "outputs": [],
   "source": [
    "## Step 8: Deploy the Application\n",
    "\n",
    "## We have deployment option: Localtunnel. Let's implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaAR5fZHAEUl",
    "outputId": "c19a98c0-7652-45e1-e1c1-005fcdea272b"
   },
   "outputs": [],
   "source": [
    "# Install Node.js and npm if not already installed\n",
    "!apt-get update -qq\n",
    "!apt-get install -y nodejs npm\n",
    "\n",
    "# Install localtunnel globally\n",
    "!npm install -g localtunnel\n",
    "\n",
    "# Navigate to the deployment directory\n",
    "%cd deployment\n",
    "\n",
    "# Launch the Streamlit app\n",
    "!streamlit run app.py &>/dev/null &\n",
    "\n",
    "# Wait a few seconds for Streamlit to start\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "# Create a tunnel using localtunnel\n",
    "!lt --port 8501\n",
    "\n",
    "print(\"\\nðŸš€ Your Audio2Art app is now deployed with localtunnel!\")\n",
    "print(\"Copy and open the URL shown above to access your application.\")\n",
    "print(\"\\nNote: This URL will only be active while this notebook is running.\")\n",
    "print(\"When you're done, run the stop cell below to stop the app.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl-xQlL-qypt"
   },
   "outputs": [],
   "source": [
    "# Stop the Streamlit app deployed with localtunnel. Remove the comment for stop.\n",
    "## !pkill -f streamlit\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
